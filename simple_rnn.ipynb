{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 0.28983727665951137\n",
      "Epoch 100/1000, Loss: 0.23855701020834816\n",
      "Epoch 200/1000, Loss: 0.22885736759293937\n",
      "Epoch 300/1000, Loss: 0.22234660747756083\n",
      "Epoch 400/1000, Loss: 0.2175194630021878\n",
      "Epoch 500/1000, Loss: 0.21359195325049182\n",
      "Epoch 600/1000, Loss: 0.21015185135650294\n",
      "Epoch 700/1000, Loss: 0.2069774736517839\n",
      "Epoch 800/1000, Loss: 0.20394643187196015\n",
      "Epoch 900/1000, Loss: 0.20098928975323774\n",
      "\n",
      "Predictions:\n",
      "[[0.57488683]\n",
      " [0.56142257]\n",
      " [0.73405938]]\n",
      "Epoch 0/1000, Loss: 0.28983727665951137\n",
      "Epoch 100/1000, Loss: 0.23855701020834816\n",
      "Epoch 200/1000, Loss: 0.22885736759293937\n",
      "Epoch 300/1000, Loss: 0.22234660747756083\n",
      "Epoch 400/1000, Loss: 0.2175194630021878\n",
      "Epoch 500/1000, Loss: 0.21359195325049182\n",
      "Epoch 600/1000, Loss: 0.21015185135650294\n",
      "Epoch 700/1000, Loss: 0.2069774736517839\n",
      "Epoch 800/1000, Loss: 0.20394643187196015\n",
      "Epoch 900/1000, Loss: 0.20098928975323774\n",
      "\n",
      "Predictions:\n",
      "[[0.57488683]\n",
      " [0.56142257]\n",
      " [0.73405938]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function: sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Loss function: Mean Squared Error\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# RNN class definition\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights\n",
    "        self.U = np.random.randn(hidden_size, input_size)  # Input to hidden\n",
    "        self.W = np.random.randn(hidden_size, hidden_size) # Hidden to hidden\n",
    "        self.V = np.random.randn(output_size, hidden_size) # Hidden to output\n",
    "\n",
    "        # Initialize biases\n",
    "        self.b = np.zeros((hidden_size, 1))\n",
    "        self.c = np.zeros((output_size, 1))\n",
    "\n",
    "        # Hidden state initialization\n",
    "        self.hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass for each time step\n",
    "        self.hidden_state = sigmoid(np.dot(self.U, x) + np.dot(self.W, self.hidden_state) + self.b)\n",
    "        y_pred = sigmoid(np.dot(self.V, self.hidden_state) + self.c)\n",
    "        return y_pred\n",
    "\n",
    "    def backward(self, x, y_true, y_pred, learning_rate=0.01):\n",
    "        # Compute output error\n",
    "        output_error = y_pred - y_true\n",
    "        output_delta = output_error * sigmoid_derivative(y_pred)\n",
    "\n",
    "        # Compute hidden error\n",
    "        hidden_error = np.dot(self.V.T, output_delta)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_state)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.V -= learning_rate * np.dot(output_delta, self.hidden_state.T)\n",
    "        self.U -= learning_rate * np.dot(hidden_delta, x.T)\n",
    "        self.W -= learning_rate * np.dot(hidden_delta, self.hidden_state.T)\n",
    "        self.b -= learning_rate * hidden_delta\n",
    "        self.c -= learning_rate * output_delta\n",
    "\n",
    "    def train(self, X, Y, epochs=1000, learning_rate=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(len(X)):\n",
    "                # Forward pass\n",
    "                x = X[i].reshape(-1, 1)\n",
    "                y_true = Y[i].reshape(-1, 1)\n",
    "                y_pred = self.forward(x)\n",
    "\n",
    "                # Compute loss\n",
    "                epoch_loss += mean_squared_error(y_true, y_pred)\n",
    "\n",
    "                # Backward pass\n",
    "                self.backward(x, y_true, y_pred, learning_rate)\n",
    "\n",
    "            # Print the loss for every 100th epoch\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch {epoch}/{epochs}, Loss: {epoch_loss / len(X)}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            x = X[i].reshape(-1, 1)\n",
    "            y_pred = self.forward(x)\n",
    "            predictions.append(y_pred.flatten())\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Sample data for demonstration\n",
    "# Input data (X): 3 samples, each with 2 features\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "# Target data (Y): 3 samples, each with 1 output\n",
    "Y = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1]\n",
    "])\n",
    "\n",
    "# Instantiate and train the RNN\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "rnn = SimpleRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the RNN\n",
    "rnn.train(X, Y, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Predict\n",
    "predictions = rnn.predict(X)\n",
    "print(\"\\nPredictions:\")\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
